from fastapi import FastAPI, UploadFile, File
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np
import cv2
import os
import uvicorn

app = FastAPI()

# ë™ì  ê²½ë¡œ ì„¤ì •: ëª¨ë¸ íŒŒì¼ ìœ„ì¹˜ ì°¾ê¸°
current_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(current_dir, 'pose_landmarker.task')

# AI ëª¨ë¸ ì´ˆê¸°í™”
base_options = python.BaseOptions(model_asset_path=model_path)
options = vision.PoseLandmarkerOptions(
    base_options=base_options,
    output_segmentation_masks=True)
detector = vision.PoseLandmarker.create_from_options(options)

@app.post("/analyze")
async def analyze_pose(photo: UploadFile = File(...)):
    print(f"ğŸ“¸ ì‚¬ì§„ ìˆ˜ì‹ : {photo.filename}")

    # 1. ì´ë¯¸ì§€ ë””ì½”ë”©
    contents = await photo.read()
    nparr = np.frombuffer(contents, np.uint8)
    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # 2. MediaPipe ë¶„ì„
    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)
    detection_result = detector.detect(mp_image)

    # 3. ëª¨ë“  ì¢Œí‘œë¥¼ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‹´ê¸°
    points = []
    if detection_result.pose_landmarks:
        for landmark in detection_result.pose_landmarks[0]:
            points.append({
                "x": landmark.x,
                "y": landmark.y,
                "z": landmark.z
            })

    print(f"âœ… ë¶„ì„ ì™„ë£Œ (ì¢Œí‘œ {len(points)}ê°œ ì¶”ì¶œ)")
    return {"status": "success", "landmarks": points}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)